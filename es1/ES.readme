

es之lucene:
    lucene是一套信息检索工具包，jar包，不包含搜索引擎系统；
    包含： 1. 索引结构； 2. 读写索引的工具；3. 网站搜索排序；4. 搜索规则(过滤和模糊)；
    es和solr是基于lucene的， java编写，开源项目；


Lucene和ES的关系：
    ES基于lucene，做了一些封装和增强；


ES简介：
    es是一个高扩展的分布式文件检索系统，es也是使用java开发，通过restful api来完成
    全文搜索，屏蔽了lucene的复杂性；
    用于:
        1. 全文搜索； 2. 结构化搜索； 3. 分析； 4. 以及这三者的混合使用；

    用途： 1. Github； 2. ELK； 3. 电商关键字； 4. 百度等；


ES和Solr的区别：

    都是用Java开发， 都是基于Lucene,  都可以独立运行， 都是向ES或者Solr
    服务器发送请求，返回xml或者json；

    ES是restful api风格， solr是web-server的api接口风格；

    1. 对单纯的数据库中已有的数据， solr速度快；
    2. 随着数据量的增加，Solr的搜索效率会降低，而ES却没有明显的变化；
    3. Solr利用Zookeeper进行分布式管理， ES自身带有分布式管理功能；
    4. Solr提供的官方功能更多，ES更注重核心功能，例如图形化需要kibana的支撑；
    5. Solr查询快，但是更新索引慢，用于电商查询多；
       ES建立索引快，实时性查询快；
    6. Solr开发社区比较成熟，ES维护开发者较少，更新较快；
    7. ES仅支持json格式， Solr支持json，xml，csv；


ELK：
    elasticsearch、 Kibana、 Logstash

    1. 通过Logstash收集清洗数据；
    2. 通过es分析数据；
    3. 通过Kibana展示数据；

    ELK常用与日志分析， 也可用于其他大数据数据清洗和分析；


1. es的安装；
    ES基于Java， 要求jdk1.8及以上，需要安装界面工具Kibana，
    ES的版本需要和之后对应的Java版本对应；
    Kibana的版本也需要和ES版本一直；

    1. 官网下载elastic和Kibana： https://www.elastic.com/ ,
        解压即可使用；

       华文云下载：
        ElasticSearch: https://mirrors.huaweicloud.com/elasticsearch/?C=N&O=D
        Logstash: https://mirrors.huaweicloud.com/logstash/?C=N&O=D
        kibana: https://mirrors.huaweicloud.com/kibana/?C=N&O=D

    2.
        启动elasticsearch:
        cd /Library/elasticsearch-7.6.0/bin && elasticsearch
        访问： localhost:9200
        es默认端口： 9200

        {
          "name" : "macOfEthandeMacBook-Pro-2.local",
          "cluster_name" : "elasticsearch", //默认集群名字
          "cluster_uuid" : "SEVCjUNAQOCQ7wkUK7w1sg", //集群id
          "version" : {
            "number" : "7.6.0", //es版本
            "build_flavor" : "default",
            "build_type" : "tar",
            "build_hash" : "7f634e9f44834fbc12724506cc1da681b0c3b1e3",
            "build_date" : "2020-02-06T00:09:00.449973Z",
            "build_snapshot" : false,
            "lucene_version" : "8.4.0", //lucene版本
            "minimum_wire_compatibility_version" : "6.8.0",
            "minimum_index_compatibility_version" : "6.0.0-beta1"
          },
          "tagline" : "You Know, for Search" //
        }

        启动Kibana:
            cd /Users/macofethan/Downloads/kibana-7.6.0-darwin-x86_64/bin/ && kibana
            localhost:5601
            kibana默认端口： 5601

          在Kibana的devtool(倒数第三个🔧图标下)，可以进行相关的测试；

        汉化Kibana：
             修改./config/kibana.yml, 重新启动kibana:
             i18n.locale: "zh-CN"


    3. 安装可视化es head的插件：
        elasticsearch-head建议只用来展示数据，查询建议用Kibana；
        基于npm， 所以需要搭建nodejs环境；
        下载地址： https://github.com/mobz/elasticsearch-head
        cd elasticsearch-head
        npm install
        npm run start

        访问： localhost:9100   默认会存在跨域问题， 需要在elasticsearch里面
        配置跨域并重新启动es服务器:

            vim ./config/elasticsearch.yml

            # 配置跨域
            http.cors.enabled: true
            http.cors.allow-origin: "*"


    4. es索引：
        如果es相当于一个数据库， 那么索引相当于一个库，文档相当于库中的数据；



面向文档： mysql与es的对比, 在es中一切都是json

    mysql            与      elasticsearch对比：
    数据库 database            索引indices (和数据库一样)
    表tables                  types (慢慢被弃用)
    行rows                    documents (数据对应文档)
    字段columns                fields



一个es索引默认情况下包含5个基于lucene的分片，所以es是利用了lucene索引进行了封装，
加上倒排索引（lucene索引）的使用使得es能够更快地找到具体的关键词，排除无关的关键词搜索；




2. es分词器 ik分词器:

    作用： 将我们提供的关键词分成多个子关键词； 比如czy分成c,z,y czy, cz等等；

   ik分词器:
    下载与安装：
    https://github.com/medcl/elasticsearch-analysis-ik, 下载对应的jar包；
    https://github.com/medcl/elasticsearch-analysis-ik/releases?after=v7.6.2
    下载完成后放入elasticsearch插件中；
    重启观察elasticsearch;
    通过elasticsearch-plugin list；查看启用的插件；


    ik分词器的两种模式：
        ik_smart: 最少切分；
        ik_max_word: 最细粒度划分；

        ik_smart模式：
        GET _analyze
        {
          "analyzer": "ik_smart",
          "text": "中国人"

        }

        将分成：
            {
              "tokens" : [
                {
                  "token" : "中国人",
                  "start_offset" : 0,
                  "end_offset" : 3,
                  "type" : "CN_WORD",
                  "position" : 0
                },
                {
                  "token" : "您好",
                  "start_offset" : 3,
                  "end_offset" : 5,
                  "type" : "CN_WORD",
                  "position" : 1
                }
              ]
            }


        ik_max_word:

        GET _analyze
        {
          "analyzer": "ik_max_word",
          "text": "中国人您好"
        }

        将分成：
        {
          "tokens" : [
            {
              "token" : "中国人",
              "start_offset" : 0,
              "end_offset" : 3,
              "type" : "CN_WORD",
              "position" : 0
            },
            {
              "token" : "中国",
              "start_offset" : 0,
              "end_offset" : 2,
              "type" : "CN_WORD",
              "position" : 1
            },
            {
              "token" : "国人",
              "start_offset" : 1,
              "end_offset" : 3,
              "type" : "CN_WORD",
              "position" : 2
            },
            {
              "token" : "您好",
              "start_offset" : 3,
              "end_offset" : 5,
              "type" : "CN_WORD",
              "position" : 3
            }
          ]
        }


    如何将某些子关键字设置为一个关键字：
      需要将这些关键字加入ik分词器中，你们ik分词器如何增加自定义配置：
      可以在ik分词器插件config文件IKAnalyzer.cfg.xml中配置扩展词典：

        <?xml version="1.0" encoding="UTF-8"?>
        <!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
        <properties>
            <comment>IK Analyzer 扩展配置</comment>
            <!--用户可以在这里配置自己的扩展字典 -->
            <entry key="ext_dict">czy.dic</entry>
             <!--用户可以在这里配置自己的扩展停止词字典-->
            <entry key="ext_stopwords"></entry>
            <!--用户可以在这里配置远程扩展字典 -->
            <!-- <entry key="remote_ext_dict">words_location</entry> -->
            <!--用户可以在这里配置远程扩展停止词字典-->
            <!-- <entry key="remote_ext_stopwords">words_location</entry> -->
        </properties>


        在IKAnalyzer.cfg.xml同级目录下新建一个czy.dic文件， 添加自定义的关键字；
        呵哈黑

        重新启动elasticsearch, 控制台会显示成功加载自定义的词典， 在Kibana中重新查询分词：
        {
          "tokens" : [
            {
              "token" : "呵哈黑",
              "start_offset" : 0,
              "end_offset" : 3,
              "type" : "CN_WORD",
              "position" : 0
            }
          ]
        }




3. es restful操作；

    #3.1, es关于索引的操作：

    method         url地址                                描述
    put         localhost:9200/索引名称/类型名称/文档id     创建文档(指定文档id)
    post        localhost:9200/索引名称/类型名称           创建文档(随机文档id)
    post        localhost:9200/索引名称/类型名称/文档id/_update   修改文档
    delete      localhost:9200/索引名称/类型名称/文档id           删除文档
    get         localhost:9200/索引名称/类型名称/文档id           通过id查找文档
    post        localhost:9200/索引名称/类型名称/_search         查询所有数据


    类型名称不指定时， 默认为_doc, 类型名称将来会被弃用，因此使用默认的就行了

    Kibana操作索引形式：
    method /索引名称/类型名称/文档id
    {
        "字段1":"字段1的值",
        "字段2":"字段2的值"
    }

    例子， 在kibana控制台：

    1. 创建索引为zs, 类型为type1， id为1的文档
        PUT /zs/type1/1
        {
          "name": "张三",
          "age":20
        }

    2. 修改索引,直接覆盖：
        PUT /zs/_doc/1
        {
          "name":"zz"
        }

        修改字段名称：
        POST /zs/_doc/1/_update
        {
          "doc":{ //所有的字段都放在doc对应下面修改
            "name":"yy"
          }
        }

    3. 产看索引信息：
        GET /zs/_doc/1


    4. 删除索引：
        会根据请求路径来删除库还是删除文档
        DELETE /zs //删除库
        DELETE /zs/_doc/1 //删除文档


    #es数据类型：
        1. 字符串类型： text, keyword
        2. 数值类型： long, integer, short, byte, double, float, half float,
                    scaled float
        3. 日期类型： date
        4. 布尔类型： boolean
        5. 二进制类型： binary
        等等



    #创建索引的时候指定字段类型：
        例子：在Kibana控制台创建一个索引，不添加文档：
        PUT /wangwu
        {
          "mappings": {
            "properties": {
              "name":{
                "type": "text"
              },
              "age":{
                "type": "integer"
              }
            }
          }
        }

        # 注意，声明的字段可以采用数组的形式添加字段值


    # 在kibana中查看es系统信息
    GET _cat/health  //查看es健康信息
    GET _cat/indices //查看索引列表



    #3.2, es关于文档的操作：

        1. 新增文档， 通过改变id新增数据：
            PUT /czy/_doc/3
            {
              "name":"王五",
              "age":"35",
              "tag":["H5", "VUE"],
              "desc":"送快递"
            }

        2. 新增数据， 建议使用post+/_update, 使用put会直接覆盖(其他字段全被被置为空)：
            POST /czy/_doc/2/_update
            {
              "doc":{
                "name":"张三"
              }
            }

            # 注意:这样相当于PUT，也会将其他字段置为空
            POST /czy/_doc/2
            {
              "doc":{
                "name":"张三"
              }
            }

        3. 查询数据：
            1. 简单的通过文档id查询
            GET /czy/_doc/2

            2.通过 /索引名称/类型名称/_search?q=key1:value1&q=key2:value2 根据关键字查找
            GET /czy/_doc/_search?q=name:王

            3. 复杂查询（排序， 分页， 高亮， 模糊查询， 精准查询）

            #1. 使用query json参数体查询：
            GET /czy/_doc/_search
            {
              "query":{
                "match":{
                  "name":"五"
                }
              }
            }

            # 查询结果
            {
              "took" : 0,
              "timed_out" : false,
              "_shards" : {
                "total" : 1,
                "successful" : 1,
                "skipped" : 0,
                "failed" : 0
              },
              "hits" : {
                "total" : {
                  "value" : 2, //匹配的总数
                  "relation" : "eq" //与关键词的关系
                },
                "max_score" : 0.8083933, //最匹配的文档的分值
                "hits" : [ //所有文档信息
                  {
                    "_index" : "czy",
                    "_type" : "_doc",
                    "_id" : "4",
                    "_score" : 0.8083933, //文档分值
                    "_source" : {
                      "name" : "赵五五",
                      "age" : 30,
                      "desc" : "zhaowu",
                      "tag" : [
                        "iOS"
                      ]
                    }
                  },
                  {
                    "_index" : "czy",
                    "_type" : "_doc",
                    "_id" : "3",
                    "_score" : 0.6682933,
                    "_source" : {
                      "name" : "王五",
                      "age" : "35",
                      "tag" : [
                        "H5",
                        "VUE"
                      ],
                      "desc" : "送快递"
                    }
                  }
                ]
              }
            }



        #2. 只查询需要的字段信息：
            GET /czy/_doc/_search
            {
              "query":{
                "match":{
                  "name":"五"
                }
              },
              "_source":["name", "age"] //结果过滤
            }


        #3. 排序
            注意： 1. text类型的字段不支持排序， 所以声明文档字段的时候最好使用
                    keyword类型或者integer类型;
                  2. keyword类型的字段，query查询时只能进行全部匹配，不能部分
                    匹配；text类型的字段可以进行部分匹配；

            //根据age升序排列
            GET /czy/_doc/_search
            {
              "sort":{
                "age":{
                  "order": "asc"
                }
              }
            }



        #4. 分页查询: from+size

            GET /czy/_doc/_search
            {
              "sort":{
                "age":{
                  "order": "asc"
                }
              },
              "from":0, //从那一页起, 起始下标
              "size":1  //查询多少条
            }


        #5. 布尔值查询, 多条件查询：

        //must： 所有条件都需要满足，相当于and；
        GET /czy/_doc/_search
        {
          "query": {
            "bool": {
              "must": [
                  {
                    "match": {
                      "name": "李四"
                    }
                  },
                  {
                    "match": {
                      "age": 10
                    }
                  }
                ]
            }
          }
        }


        //should: 相当于or
        GET /czy/_doc/_search
        {
          "query": {
            "bool": {
              "should": [
                  {
                    "match": {
                      "name": "李四"
                    }
                  },
                  {
                    "match": {
                      "age": 20
                    }
                  }
                ]
            }
          }
        }


        //must_not: 查询所有不满足条件的文档, 相当于not
        GET /czy/_doc/_search
        {
          "query": {
            "bool": {
              "must_not": [
                  {
                    "match": {
                      "age": 20
                    }
                  }
                ]
            }
          }
        }


        #6. 过滤器：

            //查询年龄小于20的数据
            //lt: 小于  gt: 大于  lte:小于等于 gte:大于等于
            GET /czy/_doc/_search
            {
              "query": {
                "bool": {
                  "filter":{
                    "range":{
                      "age":{
                        "gte": 20,  //>=20
                        "lt":50     //<50
                      }
                    }
                  }
                }
              }
            }


        #7. 匹配多个条件, 对text类型的字段可以用空格分开多个关键字，
        查询所有匹配的数据：
        GET /czy/_doc/_search
        {
          "query":{
            "match":{
              "tag":"iOS Java web"
            }
          }
        }


        #8. 精确查询：
        term查询：是直接通过倒排索引指定的词条进行精确查找的，效率较高；
        match查询： 会使用分析器，先分析文档，然后通过分析的文档进行查询；

        //单个值的精确查询
        GET /czy/_doc/_search
        {
          "query":{
            "term":{
              "age":20
            }
          }
        }

        //多个值匹配的精确查询
        GET /czy/_doc/_search
        {
          "query": {
            "bool":{
              "should":[
                  {
                    "term":{
                      "age": 20
                    }
                  },
                  {
                    "term":{
                      "name":"lisi"
                    }
                  }
                ]
            }
          }
        }


        # text类型和keyword类型的区别：
        text类型会被分词解析器解析(也就是会被分割)；
         keyword类型不会被分词解析器解析（也就是不会被分割）；

        //结果不会被拆开
        GET _analyze
        {
            "analyzer": "keyword",
            "text": "我是中国人"
        }

        //结果会被拆开
        GET _analyze
        {
            "analyzer": "standard",
            "text": "我是中国人"
        }


        #9. 高亮查询：
         GET /czy/_doc/_search
         {
           "query":{
             "match":{
               "name":"zhangsan"
             }
           },
           "highlight":{
             "pre_tags":"<p class='keywords'>", //自定义标签前缀
             "post_tags":"</p>", //自定义标签后缀
             "fields":{
               "name":{}
             }
           }
         }

         //查询出来的结果， 默认会用em标签包裹匹配的关键字：
         "hits" : [
               {
                 "_index" : "czy",
                 "_type" : "_doc",
                 "_id" : "1",
                 "_score" : 0.9808291,
                 "_source" : {
                   "name" : "zhangsan",
                   "age" : 20,
                   "desc" : "zhangsan desc",
                   "tag" : [
                     "iOS",
                     "Java"
                   ]
                 },
                 "highlight" : {
                   "name" : [
                     "<p class='keywords'>zhangsan</p>"
                   ]
                 }
               }
             ]





5. springboot集成es；

      1.



6. 爬虫抓取数据；

7. 模拟大数据量下，京东关键字搜索；
